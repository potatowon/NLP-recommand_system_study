{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CNN으로 MNIST 분류하기"
      ],
      "metadata": {
        "id": "vcuwvqGcRYLs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "Fuu4pbMSSEVR"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 합성곱(nn.Conv2d) + 활성화 함수(nn.ReLU) + 맥스풀링(nn.MaxPoold2d)을 하나의 합성곱 층\n",
        "\n",
        "inputs = torch.Tensor(1, 1, 28, 28) # batch channel height width\n"
      ],
      "metadata": {
        "id": "Y1YO_kDXRdC9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.init"
      ],
      "metadata": {
        "id": "neWWWxfnSuNL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "training_epochs = 15\n",
        "batch_size = 100"
      ],
      "metadata": {
        "id": "Vdai50r2Swk5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_train = dsets.MNIST(root='MNIST_data/', # 다운로드 경로 지정\n",
        "                          train=True, # True를 지정하면 훈련 데이터로 다운로드\n",
        "                          transform=transforms.ToTensor(), # 텐서로 변환\n",
        "                          download=True)\n",
        "\n",
        "mnist_test = dsets.MNIST(root='MNIST_data/', # 다운로드 경로 지정\n",
        "                         train=False, # False를 지정하면 테스트 데이터로 다운로드\n",
        "                         transform=transforms.ToTensor(), # 텐서로 변환\n",
        "                         download=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mib8wRnSyb1",
        "outputId": "197077a4-b1c4-4388-dd52-b21f0f20b080"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 121869655.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz to MNIST_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 101284024.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 40425842.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz to MNIST_data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 25066485.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=True,\n",
        "                                          drop_last=True)\n"
      ],
      "metadata": {
        "id": "0nZKJ51pS5bb"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vKBK--RRUnVg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        # 1번층\n",
        "        self.layer1 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        \n",
        "        # second layer\n",
        "        self.layer2 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "        # output -> linear \n",
        "        self.fc = torch.nn.Linear(7 * 7 * 64, # flatten 과정\n",
        "                                  10, # output size\n",
        "                                  bias=True)\n",
        "\n",
        "        # 전결합층 한정으로 가중치 초기화\n",
        "        torch.nn.init.xavier_uniform_(self.fc.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = out.view(out.size(0), -1)   # 전결합층을 위해서 Flatten\n",
        "        out = self.fc(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "bNWrWQWxS82A"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CNN()"
      ],
      "metadata": {
        "id": "kzeHeZzJTh1U"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()    # 비용 함수에 소프트맥스 함수 포함되어져 있음.\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "nn7JK3MZTk0z"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_batch = len(data_loader)\n",
        "\n",
        "for epoch in range(training_epochs):\n",
        "    avg_cost = 0\n",
        "\n",
        "    for X, Y in data_loader: # 미니 배치 단위로 꺼내온다. X는 미니 배치, Y느 ㄴ레이블.\n",
        "        # image is already size of (28x28), no reshape\n",
        "        # label is not one-hot encoded\n",
        "        optimizer.zero_grad()\n",
        "        hypothesis = model(X)\n",
        "        cost = criterion(hypothesis, Y)\n",
        "        cost.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        avg_cost += cost / total_batch\n",
        "\n",
        "    print('[Epoch: {:>4}] cost = {:>.9}'.format(epoch + 1, avg_cost))"
      ],
      "metadata": {
        "id": "K0NhD22PTncp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습을 진행하지 않을 것이므로 torch.no_grad()\n",
        "with torch.no_grad():\n",
        "    X_test = mnist_test.test_data.view(len(mnist_test), 1, 28, 28).float().to(device)\n",
        "    Y_test = mnist_test.test_labels\n",
        "\n",
        "    prediction = model(X_test)\n",
        "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
        "    accuracy = correct_prediction.float().mean()\n",
        "    print('Accuracy:', accuracy.item())"
      ],
      "metadata": {
        "id": "Z0J5Ut13Wece"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 깊은 모델"
      ],
      "metadata": {
        "id": "joW_LygaTqXx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.keep_prob = 0.5\n",
        "        # L1 ImgIn shape=(?, 28, 28, 1)\n",
        "        #    Conv     -> (?, 28, 28, 32)\n",
        "        #    Pool     -> (?, 14, 14, 32)\n",
        "        self.layer1 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        # L2 ImgIn shape=(?, 14, 14, 32)\n",
        "        #    Conv      ->(?, 14, 14, 64)\n",
        "        #    Pool      ->(?, 7, 7, 64)\n",
        "        self.layer2 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        # L3 ImgIn shape=(?, 7, 7, 64)\n",
        "        #    Conv      ->(?, 7, 7, 128)\n",
        "        #    Pool      ->(?, 4, 4, 128)\n",
        "        self.layer3 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=1))\n",
        "\n",
        "        # L4 FC 4x4x128 inputs -> 625 outputs\n",
        "        self.fc1 = torch.nn.Linear(4 * 4 * 128, 625, bias=True)\n",
        "        torch.nn.init.xavier_uniform_(self.fc1.weight)\n",
        "        self.layer4 = torch.nn.Sequential(\n",
        "            self.fc1,\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Dropout(p=1 - self.keep_prob))\n",
        "        # L5 Final FC 625 inputs -> 10 outputs\n",
        "        self.fc2 = torch.nn.Linear(625, 10, bias=True)\n",
        "        torch.nn.init.xavier_uniform_(self.fc2.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = out.view(out.size(0), -1)   # Flatten them for FC\n",
        "        out = self.layer4(out)\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "ImY8xxPYWWCY"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(training_epochs):\n",
        "    avg_cost = 0\n",
        "\n",
        "    for X, Y in data_loader: \n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        hypothesis = model(X)\n",
        "        cost = criterion(hypothesis, Y)\n",
        "        cost.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        avg_cost += cost / total_batch\n",
        "\n",
        "    print('[Epoch: {:>4}] cost = {:>.9}'.format(epoch + 1, avg_cost))"
      ],
      "metadata": {
        "id": "Ekzm8Bu9WWWp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}