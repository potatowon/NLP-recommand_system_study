{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\r\n",
      "  Downloading torch-2.0.0-cp310-none-macosx_10_9_x86_64.whl (139.8 MB)\r\n",
      "\u001B[K     |████████████████████████████████| 139.8 MB 14.3 MB/s eta 0:00:01    |██████████████                  | 60.8 MB 20.5 MB/s eta 0:00:04\r\n",
      "\u001B[?25hCollecting torchvision\r\n",
      "  Downloading torchvision-0.15.1-cp310-cp310-macosx_10_9_x86_64.whl (1.5 MB)\r\n",
      "\u001B[K     |████████████████████████████████| 1.5 MB 23.9 MB/s eta 0:00:01\r\n",
      "\u001B[?25hCollecting filelock\r\n",
      "  Downloading filelock-3.12.0-py3-none-any.whl (10 kB)\r\n",
      "Requirement already satisfied: typing-extensions in /Users/kim-yewon/opt/anaconda3/envs/MLp/lib/python3.10/site-packages (from torch) (4.4.0)\r\n",
      "Collecting sympy\r\n",
      "  Downloading sympy-1.11.1-py3-none-any.whl (6.5 MB)\r\n",
      "\u001B[K     |████████████████████████████████| 6.5 MB 32.9 MB/s eta 0:00:01\r\n",
      "\u001B[?25hRequirement already satisfied: jinja2 in /Users/kim-yewon/opt/anaconda3/envs/MLp/lib/python3.10/site-packages (from torch) (3.1.2)\r\n",
      "Collecting networkx\r\n",
      "  Downloading networkx-3.1-py3-none-any.whl (2.1 MB)\r\n",
      "\u001B[K     |████████████████████████████████| 2.1 MB 14.7 MB/s eta 0:00:01\r\n",
      "\u001B[?25hRequirement already satisfied: numpy in /Users/kim-yewon/opt/anaconda3/envs/MLp/lib/python3.10/site-packages (from torchvision) (1.22.3)\r\n",
      "Requirement already satisfied: requests in /Users/kim-yewon/opt/anaconda3/envs/MLp/lib/python3.10/site-packages (from torchvision) (2.28.1)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/kim-yewon/opt/anaconda3/envs/MLp/lib/python3.10/site-packages (from torchvision) (9.2.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/kim-yewon/opt/anaconda3/envs/MLp/lib/python3.10/site-packages (from jinja2->torch) (2.1.1)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/kim-yewon/opt/anaconda3/envs/MLp/lib/python3.10/site-packages (from requests->torchvision) (2022.12.7)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/kim-yewon/opt/anaconda3/envs/MLp/lib/python3.10/site-packages (from requests->torchvision) (3.4)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/kim-yewon/opt/anaconda3/envs/MLp/lib/python3.10/site-packages (from requests->torchvision) (1.26.14)\r\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/kim-yewon/opt/anaconda3/envs/MLp/lib/python3.10/site-packages (from requests->torchvision) (2.0.4)\r\n",
      "Collecting mpmath>=0.19\r\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\r\n",
      "\u001B[K     |████████████████████████████████| 536 kB 49.5 MB/s eta 0:00:01\r\n",
      "\u001B[?25hInstalling collected packages: mpmath, sympy, networkx, filelock, torch, torchvision\r\n",
      "Successfully installed filelock-3.12.0 mpmath-1.3.0 networkx-3.1 sympy-1.11.1 torch-2.0.0 torchvision-0.15.1\r\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "서비스를 배포한다고 가정했을때, 어떤 컴퓨터에서도 동일한 결과를 얻어야한다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "<torch._C.Generator at 0x7fa8c8937db0>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델링을 연습하는 과정에서는 randomseed 를 고정해주는 것이 좋다.\n",
    "\n",
    "torch.manual_seed(1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 데이터 선언"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1]) torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "x_train = torch.FloatTensor([[1], [2], [3]])\n",
    "y_train = torch.FloatTensor([[2], [4], [6]])\n",
    "\n",
    "print(x_train.size(), y_train.size())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# weight 와 bias 초기화\n",
    "\n",
    "- tensorflow 의 경우는 변수함수를 이용하여 변수임을 지정 \\\n",
    "`requires_grad` 를 이용하여 지정"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1]) torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "W = torch.zeros(1, requires_grad=True)  # 변경되는 변수임을 선언\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "print(W.size(), b.size())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 선형회귀 모델\n",
    "\n",
    "- 가설세우기\n",
    "- 비용함수\n",
    "- 최적화(경사하강법)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "## 가설세우기 ##\n",
    "hypothesis = x_train * W + b\n",
    "print(hypothesis)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(16., grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "## cost function ##\n",
    "cost = torch.mean(hypothesis - y_train)**2 # mse : mean squre error\n",
    "print(cost)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "## 경사하강법 구현 ##\n",
    "\n",
    "optimizer = optim.SGD([W, b], lr=0.01) # lr = learning rate\n",
    "\n",
    "# gradient를 0으로 초기화 하고 시작\n",
    "\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# 비용함수를 미분하여 최적화\n",
    "cost.backward()\n",
    "\n",
    "# W, b 를 업데이트\n",
    "optimizer.step()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1600], requires_grad=True) tensor([0.0800], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(W, b) # 한번의 과정을 거쳤을 경우"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0 W: 1.803, b: 0.448 Cost: 0.030275\n",
      "Epoch    1 W: 1.808, b: 0.438 Cost: 0.028837\n",
      "Epoch    2 W: 1.812, b: 0.427 Cost: 0.027467\n",
      "Epoch    3 W: 1.817, b: 0.417 Cost: 0.026162\n",
      "Epoch    4 W: 1.821, b: 0.407 Cost: 0.024919\n",
      "Epoch    5 W: 1.825, b: 0.397 Cost: 0.023736\n",
      "Epoch    6 W: 1.830, b: 0.387 Cost: 0.022608\n",
      "Epoch    7 W: 1.834, b: 0.378 Cost: 0.021534\n",
      "Epoch    8 W: 1.838, b: 0.369 Cost: 0.020511\n",
      "Epoch    9 W: 1.842, b: 0.360 Cost: 0.019537\n",
      "Epoch   10 W: 1.845, b: 0.352 Cost: 0.018609\n",
      "Epoch   11 W: 1.849, b: 0.343 Cost: 0.017725\n",
      "Epoch   12 W: 1.853, b: 0.335 Cost: 0.016883\n",
      "Epoch   13 W: 1.856, b: 0.327 Cost: 0.016081\n",
      "Epoch   14 W: 1.860, b: 0.319 Cost: 0.015317\n",
      "Epoch   15 W: 1.863, b: 0.311 Cost: 0.014590\n",
      "Epoch   16 W: 1.866, b: 0.304 Cost: 0.013897\n",
      "Epoch   17 W: 1.870, b: 0.296 Cost: 0.013237\n",
      "Epoch   18 W: 1.873, b: 0.289 Cost: 0.012608\n",
      "Epoch   19 W: 1.876, b: 0.282 Cost: 0.012009\n",
      "Epoch   20 W: 1.879, b: 0.276 Cost: 0.011439\n",
      "Epoch   21 W: 1.882, b: 0.269 Cost: 0.010895\n",
      "Epoch   22 W: 1.885, b: 0.262 Cost: 0.010378\n",
      "Epoch   23 W: 1.887, b: 0.256 Cost: 0.009885\n",
      "Epoch   24 W: 1.890, b: 0.250 Cost: 0.009415\n",
      "Epoch   25 W: 1.893, b: 0.244 Cost: 0.008968\n",
      "Epoch   26 W: 1.895, b: 0.238 Cost: 0.008542\n",
      "Epoch   27 W: 1.898, b: 0.232 Cost: 0.008136\n",
      "Epoch   28 W: 1.900, b: 0.227 Cost: 0.007750\n",
      "Epoch   29 W: 1.903, b: 0.221 Cost: 0.007382\n",
      "Epoch   30 W: 1.905, b: 0.216 Cost: 0.007031\n",
      "Epoch   31 W: 1.907, b: 0.211 Cost: 0.006697\n",
      "Epoch   32 W: 1.909, b: 0.206 Cost: 0.006379\n",
      "Epoch   33 W: 1.912, b: 0.201 Cost: 0.006076\n",
      "Epoch   34 W: 1.914, b: 0.196 Cost: 0.005787\n",
      "Epoch   35 W: 1.916, b: 0.191 Cost: 0.005512\n",
      "Epoch   36 W: 1.918, b: 0.187 Cost: 0.005251\n",
      "Epoch   37 W: 1.920, b: 0.182 Cost: 0.005001\n",
      "Epoch   38 W: 1.922, b: 0.178 Cost: 0.004764\n",
      "Epoch   39 W: 1.924, b: 0.174 Cost: 0.004537\n",
      "Epoch   40 W: 1.925, b: 0.169 Cost: 0.004322\n",
      "Epoch   41 W: 1.927, b: 0.165 Cost: 0.004116\n",
      "Epoch   42 W: 1.929, b: 0.161 Cost: 0.003921\n",
      "Epoch   43 W: 1.931, b: 0.157 Cost: 0.003735\n",
      "Epoch   44 W: 1.932, b: 0.154 Cost: 0.003557\n",
      "Epoch   45 W: 1.934, b: 0.150 Cost: 0.003388\n",
      "Epoch   46 W: 1.936, b: 0.146 Cost: 0.003227\n",
      "Epoch   47 W: 1.937, b: 0.143 Cost: 0.003074\n",
      "Epoch   48 W: 1.939, b: 0.139 Cost: 0.002928\n",
      "Epoch   49 W: 1.940, b: 0.136 Cost: 0.002789\n",
      "Epoch   50 W: 1.942, b: 0.133 Cost: 0.002657\n",
      "Epoch   51 W: 1.943, b: 0.130 Cost: 0.002530\n",
      "Epoch   52 W: 1.944, b: 0.127 Cost: 0.002410\n",
      "Epoch   53 W: 1.946, b: 0.123 Cost: 0.002296\n",
      "Epoch   54 W: 1.947, b: 0.120 Cost: 0.002187\n",
      "Epoch   55 W: 1.948, b: 0.118 Cost: 0.002083\n",
      "Epoch   56 W: 1.950, b: 0.115 Cost: 0.001984\n",
      "Epoch   57 W: 1.951, b: 0.112 Cost: 0.001890\n",
      "Epoch   58 W: 1.952, b: 0.109 Cost: 0.001800\n",
      "Epoch   59 W: 1.953, b: 0.107 Cost: 0.001714\n",
      "Epoch   60 W: 1.954, b: 0.104 Cost: 0.001633\n",
      "Epoch   61 W: 1.955, b: 0.102 Cost: 0.001555\n",
      "Epoch   62 W: 1.956, b: 0.099 Cost: 0.001481\n",
      "Epoch   63 W: 1.957, b: 0.097 Cost: 0.001411\n",
      "Epoch   64 W: 1.958, b: 0.094 Cost: 0.001344\n",
      "Epoch   65 W: 1.959, b: 0.092 Cost: 0.001280\n",
      "Epoch   66 W: 1.960, b: 0.090 Cost: 0.001219\n",
      "Epoch   67 W: 1.961, b: 0.088 Cost: 0.001161\n",
      "Epoch   68 W: 1.962, b: 0.086 Cost: 0.001106\n",
      "Epoch   69 W: 1.963, b: 0.084 Cost: 0.001054\n",
      "Epoch   70 W: 1.964, b: 0.082 Cost: 0.001004\n",
      "Epoch   71 W: 1.965, b: 0.080 Cost: 0.000956\n",
      "Epoch   72 W: 1.966, b: 0.078 Cost: 0.000911\n",
      "Epoch   73 W: 1.967, b: 0.076 Cost: 0.000867\n",
      "Epoch   74 W: 1.967, b: 0.074 Cost: 0.000826\n",
      "Epoch   75 W: 1.968, b: 0.072 Cost: 0.000787\n",
      "Epoch   76 W: 1.969, b: 0.071 Cost: 0.000750\n",
      "Epoch   77 W: 1.970, b: 0.069 Cost: 0.000714\n",
      "Epoch   78 W: 1.970, b: 0.067 Cost: 0.000680\n",
      "Epoch   79 W: 1.971, b: 0.066 Cost: 0.000648\n",
      "Epoch   80 W: 1.972, b: 0.064 Cost: 0.000617\n",
      "Epoch   81 W: 1.973, b: 0.062 Cost: 0.000588\n",
      "Epoch   82 W: 1.973, b: 0.061 Cost: 0.000560\n",
      "Epoch   83 W: 1.974, b: 0.059 Cost: 0.000533\n",
      "Epoch   84 W: 1.974, b: 0.058 Cost: 0.000508\n",
      "Epoch   85 W: 1.975, b: 0.057 Cost: 0.000484\n",
      "Epoch   86 W: 1.976, b: 0.055 Cost: 0.000461\n",
      "Epoch   87 W: 1.976, b: 0.054 Cost: 0.000439\n",
      "Epoch   88 W: 1.977, b: 0.053 Cost: 0.000418\n",
      "Epoch   89 W: 1.977, b: 0.051 Cost: 0.000398\n",
      "Epoch   90 W: 1.978, b: 0.050 Cost: 0.000379\n",
      "Epoch   91 W: 1.978, b: 0.049 Cost: 0.000361\n",
      "Epoch   92 W: 1.979, b: 0.048 Cost: 0.000344\n",
      "Epoch   93 W: 1.979, b: 0.047 Cost: 0.000328\n",
      "Epoch   94 W: 1.980, b: 0.046 Cost: 0.000312\n",
      "Epoch   95 W: 1.980, b: 0.044 Cost: 0.000297\n",
      "Epoch   96 W: 1.981, b: 0.043 Cost: 0.000283\n",
      "Epoch   97 W: 1.981, b: 0.042 Cost: 0.000270\n",
      "Epoch   98 W: 1.982, b: 0.041 Cost: 0.000257\n",
      "Epoch   99 W: 1.982, b: 0.040 Cost: 0.000245\n",
      "tensor([1.9823], requires_grad=True) tensor([0.0403], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "## 경사하강법을 반복하여 최적화\n",
    "optimizer = optim.SGD([W, b], lr=0.1) # lr = learning rate\n",
    "\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "for num in range(epochs):\n",
    "\n",
    "    hypothesis = x_train * W + b\n",
    "\n",
    "    cost = torch.mean((hypothesis - y_train)**2)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print('Epoch {:4d} W: {:.3f}, b: {:.3f} Cost: {:.6f}'.format(\n",
    "       num, W.item(), b.item(), cost.item()\n",
    "    ))\n",
    "\n",
    "print(W, b)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### `optimizer.zero_grad()` 가 필요한 이유\n",
    "\n",
    "파이토치는 미분을 통해 얻은 기울기는 이전에 계산된 기울기 값에 누적시키는 특징이 있다. \\\n",
    "따라서 값을 계속해서 합산하므로 \\\n",
    "미분값을 0으로 초기화 해주는 과정이 필요하다"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
